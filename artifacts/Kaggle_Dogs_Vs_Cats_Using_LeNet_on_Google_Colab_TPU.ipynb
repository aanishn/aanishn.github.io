{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Dogs Vs. Cats Using LeNet on Google Colab TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0Rp_aK2rFM4d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Kaggle Dogs Vs. Cats Using LeNet  on Google Colab TPU\n",
        "=================================================="
      ]
    },
    {
      "metadata": {
        "id": "RGpaBWyhGcjK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Required setup\n",
        "\n",
        "1. Update api_token with kaggle api key for downloading dataset\n",
        "\n",
        "          - Login to kaggle\n",
        "          - My Profile > Edit Profile > Createt new API Token\n",
        "          - Update **api_token** dict below with the values\n",
        "          \n",
        "2. Change Notebook runtime to TPU\n",
        "          \n",
        "          - In colab notebook menu, Runtime > Change runtime type\n",
        "          - Select TPU in the list"
      ]
    },
    {
      "metadata": {
        "id": "-vy8CfzwGtrp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install kaggle package, download and extract zip file"
      ]
    },
    {
      "metadata": {
        "id": "jO5ngCbbB0O6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "outputId": "cc5e42d1-a7d7-4a6a-e615-78f2b7712762"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "api_token = {\"username\":\"xxxxx\",\"key\":\"xxxxxxxxxxxxxxxxxxxxxxxx\"}\n",
        "\n",
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.mkdir('/root/.kaggle')\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle config path -p /root\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K    3% |█                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K    6% |██                              | 20kB 5.4MB/s eta 0:00:01\r\u001b[K    9% |███▏                            | 30kB 6.0MB/s eta 0:00:01\r\u001b[K    13% |████▏                           | 40kB 5.7MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 51kB 5.8MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 61kB 6.8MB/s eta 0:00:01\r\u001b[K    22% |███████▍                        | 71kB 6.3MB/s eta 0:00:01\r\u001b[K    26% |████████▍                       | 81kB 6.4MB/s eta 0:00:01\r\u001b[K    29% |█████████▍                      | 92kB 7.1MB/s eta 0:00:01\r\u001b[K    32% |██████████▌                     | 102kB 6.9MB/s eta 0:00:01\r\u001b[K    36% |███████████▌                    | 112kB 7.0MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 122kB 7.9MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 133kB 8.1MB/s eta 0:00:01\r\u001b[K    45% |██████████████▊                 | 143kB 9.6MB/s eta 0:00:01\r\u001b[K    49% |███████████████▊                | 153kB 9.6MB/s eta 0:00:01\r\u001b[K    52% |████████████████▊               | 163kB 8.4MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▉              | 174kB 10.1MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▉             | 184kB 10.3MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 194kB 10.4MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 204kB 10.5MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 215kB 9.0MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████         | 225kB 10.2MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▏       | 235kB 9.6MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 245kB 9.2MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 256kB 10.5MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▎    | 266kB 10.1MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▎   | 276kB 10.2MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▍  | 286kB 10.7MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▍ | 296kB 8.6MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 307kB 9.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 317kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.1.6\n",
            "    Uninstalling Keras-2.1.6:\n",
            "      Successfully uninstalled Keras-2.1.6\n",
            "Successfully installed keras-2.2.4\n",
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/78/832b9a9ec6b3baf8ec566e1f0a695f2fd08d2c94a6797257a106304bfc3c/kaggle-1.4.7.1.tar.gz (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.10.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.27.0)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 11.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
            "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/44/2c/df/22a6eeb780c36c28190faef6252b739fdc47145fd87a6642d4\n",
            "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
            "Successfully built kaggle python-slugify\n",
            "Installing collected packages: Unidecode, python-slugify, kaggle\n",
            "Successfully installed Unidecode-1.0.22 kaggle-1.4.7.1 python-slugify-1.2.6\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 37.5MB/s]\n",
            "Downloading test1.zip to /content\n",
            " 95% 257M/271M [00:01<00:00, 111MB/s]\n",
            "100% 271M/271M [00:02<00:00, 137MB/s]\n",
            "Downloading train.zip to /content\n",
            " 97% 529M/543M [00:03<00:00, 198MB/s]\n",
            "100% 543M/543M [00:03<00:00, 159MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p3BnCi9BEkQU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('/content/train.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upnoV_c0GpD7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Re-arrange classes to 2 separate directories"
      ]
    },
    {
      "metadata": {
        "id": "Z7vuGf6Yr5hX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir train/cat train/dog\n",
        "!mv train/*cat*.jpg train/cat\n",
        "!mv train/*dog*.jpg train/dog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMg76okuHEQp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training configs"
      ]
    },
    {
      "metadata": {
        "id": "9TZsVv8xtMIv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE   = 64\n",
        "IMG_DIM      = (256, 256, 3)\n",
        "NUM_EPOCHS   = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5i_ASwDQHHQO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup generators to provide with train and validation batches"
      ]
    },
    {
      "metadata": {
        "id": "Ibhd3nFqWssc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "e07fff16-955c-4706-bfa2-6d780b5f6933"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)\n",
        "\n",
        "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2)\n",
        "\n",
        "traingen = datagen.flow_from_directory(\n",
        "    'train',\n",
        "    batch_size = BATCH_SIZE,\n",
        "    target_size = IMG_DIM[:-1],\n",
        "    class_mode = 'categorical',\n",
        "    subset='training')\n",
        "\n",
        "valgen = datagen.flow_from_directory(\n",
        "    'train',\n",
        "    batch_size = BATCH_SIZE,\n",
        "    target_size = IMG_DIM[:-1],\n",
        "    class_mode = 'categorical',\n",
        "    subset='validation')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.6-tf\n",
            "1.11.0\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1w_7F2B0HTbr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define LeNet model architecture"
      ]
    },
    {
      "metadata": {
        "id": "rr2eO46XGoWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "27e430e5-e377-42b5-8fdd-899a4542f899"
      },
      "cell_type": "code",
      "source": [
        "input = keras.layers.Input(IMG_DIM, name=\"input\")\n",
        "conv1 = keras.layers.Conv2D(20, kernel_size=(5, 5), padding='same')(input)\n",
        "pool1 = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv1)\n",
        "conv2 = keras.layers.Conv2D(50, kernel_size=(5,5), padding='same')(pool1)\n",
        "pool2 = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(conv1)\n",
        "flatten1 = keras.layers.Flatten()(pool2)\n",
        "fc1 = keras.layers.Dense(500, activation='relu')(flatten1)\n",
        "fc2 = keras.layers.Dense(2, activation='softmax')(fc1)\n",
        "\n",
        "model = keras.models.Model(inputs=input, outputs=fc2)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 256, 256, 20)      1520      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 20)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 327680)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               163840500 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1002      \n",
            "=================================================================\n",
            "Total params: 163,843,022\n",
            "Trainable params: 163,843,022\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uyp15GI2HaDV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check for TPU availability"
      ]
    },
    {
      "metadata": {
        "id": "GcvqN_K__R36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d11ee971-8545-495c-9a40-19c5dcbfd8a8"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "  print('TPU not found')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.73.36.106:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V81b4_HyIVup",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert keras model to TPU model"
      ]
    },
    {
      "metadata": {
        "id": "ZMDvrNwH_tzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "a4f0aafd-05a6-4870-a7a4-6e4b21bd57f7"
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.73.36.106:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4430250600885613814)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14860921772671154020)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 10329331434607546216)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3020471452782936925)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7058080726911325303)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 616613029749391519)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11136912683004452860)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4887088926811133454)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2967281305396391452)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 287043896194918914)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7338422145717968905)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 11776534234889956760)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Connecting to: b'grpc://10.73.36.106:8470'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L2L4OjkmIi0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run training"
      ]
    },
    {
      "metadata": {
        "id": "i95Fgn1CNMq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "55551ae0-4f6f-4789-bc73-b3885f06b982"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit_generator(\n",
        "    traingen,\n",
        "    steps_per_epoch=traingen.n//traingen.batch_size,\n",
        "    epochs=1,\n",
        "    validation_data=valgen,\n",
        "    validation_steps=valgen.n//valgen.batch_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(8, 256, 256, 3), dtype=tf.float32, name='input_20'), TensorSpec(shape=(8, 2), dtype=tf.float32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.0, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Get updates: Tensor(\"loss/mul:0\", shape=(), dtype=float32)\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 28.781575918197632 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "  5/312 [..............................] - ETA: 43:10 - loss: 1.3635 - acc: 0.5250INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(4, 256, 256, 3), dtype=tf.float32, name='input_20'), TensorSpec(shape=(4, 2), dtype=tf.float32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.0, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Get updates: Tensor(\"loss_1/mul:0\", shape=(), dtype=float32)\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 15.506837844848633 secs\n",
            "311/312 [============================>.] - ETA: 1s - loss: 0.6510 - acc: 0.6254INFO:tensorflow:New input shapes; (re-)compiling: mode=eval, [TensorSpec(shape=(8, 256, 256, 3), dtype=tf.float32, name='input_20'), TensorSpec(shape=(8, 2), dtype=tf.float32, name='dense_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.0, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 23.947693347930908 secs\n",
            "312/312 [==============================] - 495s 2s/step - loss: 0.6512 - acc: 0.6246 - val_loss: 0.6025 - val_acc: 0.6522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f674345db70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "bmspdyDlImR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the model weights"
      ]
    },
    {
      "metadata": {
        "id": "fD01HqUUDS0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "37867fd8-1589-49e6-c697-ad70229d3846"
      },
      "cell_type": "code",
      "source": [
        "tpu_model.save_weights('./lenet-catdog.h5', overwrite=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RV9sgul7IpvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download model weights locally"
      ]
    },
    {
      "metadata": {
        "id": "mL_zCvAREp1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"lenet-catdog.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}